{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66ab3cc5-aee4-415a-9391-1e5d37ccaf1d",
   "metadata": {},
   "source": [
    "# Q&A against a SQL Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306fc0a9-4044-441d-9ba7-f54f32e6ea9f",
   "metadata": {},
   "source": [
    "Now that we know (from the prior Notebook) how to query tabular data on a CSV file, let's try now to keep the data at is source and ask questions directly to a SQL Database.\n",
    "The goal of this notebook is to demonstrate how a LLM so advanced as GPT-4 can understand a human question and translate that into a SQL query to get the answer. \n",
    "\n",
    "We will be using the Azure SQL Server that you created on the initial deployment. The server should be created on the Resource Group where the Azure Cognitive Search service is located.\n",
    "\n",
    "Let's begin.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1fb79a3-4856-4721-988c-112813690a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain import SQLDatabaseChain\n",
    "\n",
    "from app.prompts import MSSQL_PROMPT\n",
    "\n",
    "# Don't mess with this unless you really know what you are doing\n",
    "AZURE_OPENAI_API_VERSION = \"2023-03-15-preview\"\n",
    "\n",
    "# Change these below with your own services credentials\n",
    "AZURE_OPENAI_ENDPOINT = \"Enter your Azure OpenAI Endpoint ...\"\n",
    "AZURE_OPENAI_API_KEY = \"Enter your Azure OpenAI Key ...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "258a6e99-2d4f-4147-b8ee-c64c85296181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
    "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"AZURE_OPENAI_ENDPOINT\"] = AZURE_OPENAI_ENDPOINT\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"AZURE_OPENAI_API_KEY\"] = AZURE_OPENAI_API_KEY\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"] = AZURE_OPENAI_API_VERSION\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8e0b32-a6b5-4b1c-943d-e57b737213fa",
   "metadata": {},
   "source": [
    "# Install MS SQL DB driver in your machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a353df6-0966-4e43-a914-6a2856eb140a",
   "metadata": {},
   "source": [
    "We need the driver installed on this compute in order to talk to the SQL DB, so run the below cell once<br>\n",
    "Reference: https://learn.microsoft.com/en-us/sql/connect/odbc/linux-mac/installing-the-microsoft-odbc-driver-for-sql-server?view=sql-server-ver16&tabs=ubuntu18-install%2Calpine17-install%2Cdebian8-install%2Credhat7-13-install%2Crhel7-offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65fbffc7-e149-4eb3-a4db-9f114b06f205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo ./download_odbc_driver.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e30fa1-877d-4d3b-80b0-e17459c1e4f4",
   "metadata": {},
   "source": [
    "# Load Azure SQL DB with the Covid Tracking CSV Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4352dca-7159-4e41-983d-2c6951cf18db",
   "metadata": {},
   "source": [
    "The Azure SQL Database is currently empty, so we need to fill it up with data. Let's use the same data on the Covid CSV filed we used on the prior Notebook, that way we can compare results and methods. \n",
    "For this, you will need to type below the credentials you used at creation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26739d89-e075-4098-ab38-92cccf9f9425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful!\n",
      "('Microsoft SQL Azure (RTM) - 12.0.2000.8 \\n\\tMar  8 2023 17:58:50 \\n\\tCopyright (C) 2022 Microsoft Corporation\\n',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2430106/2265681346.py:36: RemovedIn20Warning: Deprecated API features detected! These feature(s) are not compatible with SQLAlchemy 2.0. To prevent incompatible upgrades prior to updating applications, ensure requirements files are pinned to \"sqlalchemy<2.0\". Set environment variable SQLALCHEMY_WARN_20=1 to show all deprecation warnings.  Set environment variable SQLALCHEMY_SILENCE_UBER_WARNING=1 to silence this message. (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  result = engine.execute(\"SELECT @@Version\")\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine.url import URL\n",
    "\n",
    "# Define the parameters for the database connection\n",
    "server = '<YOUR_SERVER_NAME>.database.windows.net'\n",
    "database = '<YOUR_DATABASE_NAME>'\n",
    "username = '<YOUR_DB_USERNAME>'\n",
    "password = '<YOUR_DB_PASSWORD>'\n",
    "\n",
    "# Don't change this driver variable\n",
    "driver= '{ODBC Driver 18 for SQL Server}'\n",
    "\n",
    "db_config = {\n",
    "    'drivername': 'mssql+pyodbc',\n",
    "    'username': username+'@'+server,\n",
    "    'password': password,\n",
    "    'host': server,\n",
    "    'port': 1433,\n",
    "    'database': database,\n",
    "    'query': {'driver': 'ODBC Driver 18 for SQL Server'}\n",
    "}\n",
    "\n",
    "# Create a URL object for connecting to the database\n",
    "db_url = URL.create(**db_config)\n",
    "\n",
    "# Print the resulting URL string\n",
    "# print(db_url)\n",
    "\n",
    "# Connect to the Azure SQL Database using the URL string\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "# Test the connection\n",
    "try:\n",
    "    conn = engine.connect()\n",
    "    print(\"Connection successful!\")\n",
    "    result = engine.execute(\"SELECT @@Version\")\n",
    "    for row in result:\n",
    "        print(row)\n",
    "    conn.close()\n",
    "    \n",
    "except OperationalError:\n",
    "    print(\"Connection failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acaf202c-33a1-4105-b506-c26f2080c1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(pyodbc.ProgrammingError) ('42S01', \"[42S01] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]There is already an object named 'covidtracking' in the database. (2714) (SQLExecDirectW)\")\n",
      "[SQL: CREATE TABLE covidtracking (date VARCHAR(255), state VARCHAR(255), death FLOAT, deathConfirmed FLOAT, deathIncrease INT, deathProbable FLOAT, hospitalized FLOAT, hospitalizedCumulative FLOAT, hospitalizedCurrently FLOAT, hospitalizedIncrease INT, inIcuCumulative FLOAT, inIcuCurrently FLOAT, negative FLOAT, negativeIncrease INT, negativeTestsAntibody FLOAT, negativeTestsPeopleAntibody FLOAT, negativeTestsViral FLOAT, onVentilatorCumulative FLOAT, onVentilatorCurrently FLOAT, positive FLOAT, positiveCasesViral FLOAT, positiveIncrease INT, positiveScore INT, positiveTestsAntibody FLOAT, positiveTestsAntigen FLOAT, positiveTestsPeopleAntibody FLOAT, positiveTestsPeopleAntigen FLOAT, positiveTestsViral FLOAT, recovered FLOAT, totalTestEncountersViral FLOAT, totalTestEncountersViralIncrease INT, totalTestResults FLOAT, totalTestResultsIncrease INT, totalTestsAntibody FLOAT, totalTestsAntigen FLOAT, totalTestsPeopleAntibody FLOAT, totalTestsPeopleAntigen FLOAT, totalTestsPeopleViral FLOAT, totalTestsPeopleViralIncrease INT, totalTestsViral FLOAT, totalTestsViralIncrease INT)]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n",
      "Table 'covidtracking' already exists.\n"
     ]
    }
   ],
   "source": [
    "# Read CSV file into a pandas dataframe\n",
    "csv_path = \"./data/all-states-history.csv\"\n",
    "df = pd.read_csv(csv_path).fillna(value = 0)\n",
    "\n",
    "# Infer column names and data types\n",
    "column_names = df.columns.tolist()\n",
    "column_types = df.dtypes.to_dict()\n",
    "\n",
    "# Generate SQL statement to create table\n",
    "table_name = 'covidtracking'\n",
    "\n",
    "create_table_sql = f\"CREATE TABLE {table_name} (\"\n",
    "for name, dtype in column_types.items():\n",
    "    if dtype == 'object':\n",
    "        create_table_sql += f\"{name} VARCHAR(255), \"\n",
    "    elif dtype == 'int64':\n",
    "        create_table_sql += f\"{name} INT, \"\n",
    "    elif dtype == 'float64':\n",
    "        create_table_sql += f\"{name} FLOAT, \"\n",
    "    elif dtype == 'bool':\n",
    "        create_table_sql += f\"{name} BIT, \"\n",
    "    elif dtype == 'datetime64[ns]':\n",
    "        create_table_sql += f\"{name} DATETIME, \"\n",
    "create_table_sql = create_table_sql[:-2] + \")\"\n",
    "\n",
    "try:\n",
    "    engine.execute(create_table_sql)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "# Insert data into SQL Database\n",
    "try:\n",
    "    df.to_sql(table_name, con=engine, if_exists='fail', index=False)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ad46af-11a4-41a6-94af-15509fd9e16c",
   "metadata": {},
   "source": [
    "# Query with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7faef3c0-8166-4f3b-a5e3-d30acfd65fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or LLM Langchain object using GPT-4 deployment\n",
    "llm = AzureChatOpenAI(deployment_name=\"gpt-4\", temperature=0, max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cbe650c-9e0a-4209-9595-de13f2f1ee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use a type of Chain made for this type of SQL work.  \n",
    "db = SQLDatabase.from_uri(db_url)\n",
    "db_chain = SQLDatabaseChain(llm=llm, database=db, prompt=MSSQL_PROMPT, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad678667-9031-4140-a060-2e5dc46799b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an MS SQL expert. Given an input question, first create a syntactically correct MS SQL query to run, then look at the results of the query and return the answer to the input question.\n",
      "\n",
      "Unless the user specifies in the question a specific number of examples to obtain, query for at most {top_k} results using the TOP clause as per MS SQL. You can order the results to return the most informative data in the database.\n",
      "\n",
      "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in square brackets ([]) to denote them as delimited identifiers.\n",
      "\n",
      "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "\n",
      "## **Do not use double quotes on the SQL query**. \n",
      "\n",
      "** ALWAYS before giving the Final Answer, try another method**. Then reflect on the answers of the two methods you did and ask yourself if it answers correctly the original question. If you are not sure, try another method.\n",
      "If the runs does not give the same result, reflect and try again two more times until you have two runs that have the same result. If you still cannot arrive to a consistent result, say that you are not sure of the answer. But, if you are sure of the correct answer, create a beautiful and thorough response. DO NOT MAKE UP AN ANSWER OR USE PRIOR KNOWLEDGE, ONLY USE THE RESULTS OF THE CALCULATIONS YOU HAVE DONE. \n",
      "\n",
      "ALWAYS, as part of your final answer, explain how you got to the answer on a section that starts with: \n",
      "\n",
      "Explanation:\n",
      ".'\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: \"Question here\"\n",
      "SQLQuery: \"SQL Query to run\"\n",
      "SQLResult: \"Result of the SQLQuery\"\n",
      "Answer: \"Final answer here\"\n",
      "Explanation:\n",
      "\n",
      "Only use the following tables:\n",
      "{table_info}\n",
      "\n",
      "Question: {input}\n"
     ]
    }
   ],
   "source": [
    "# Let's check our prompt we created \n",
    "print(db_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae80c022-415e-40d1-b205-1744a3164d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natural Language question (query)\n",
    "query_str = 'How may patients in total were hospitalized during July 2020 in Texas, and nationwide?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16c2b905-64b8-4fdc-8fc8-7c0274ec6a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "How may patients in total were hospitalized during July 2020 in Texas, and nationwide?\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT [state], SUM([hospitalizedIncrease]) as TotalHospitalized\n",
      "FROM covidtracking\n",
      "WHERE [date] >= '2020-07-01' AND [date] <= '2020-07-31'\n",
      "GROUP BY [state]\n",
      "ORDER BY [state]\n",
      "\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[('AK', 83), ('AL', 7752), ('AR', 1439), ('AS', 0), ('AZ', 6524), ('CA', 0), ('CO', 952), ('CT', 539), ('DC', 0), ('DE', 0), ('FL', 12026), ('GA', 7638), ('GU', 0), ('HI', 66), ('IA', 0), ('ID', 513), ('IL', 0), ('IN', 1662), ('KS', 599), ('KY', 693), ('LA', 0), ('MA', 571), ('MD', 1749), ('ME', 40), ('MI', 0), ('MN', 1101), ('MO', 0), ('MP', 4), ('MS', 1120), ('MT', 129), ('NC', 0), ('ND', 133), ('NE', 280), ('NH', 128), ('NJ', 1718), ('NM', 784), ('NV', 0), ('NY', 0), ('OH', 2951), ('OK', 1641), ('OR', 562), ('PA', 0), ('PR', 0), ('RI', 210), ('SC', 2263), ('SD', 158), ('TN', 1996), ('TX', 0), ('UT', 933), ('VA', 1663), ('VI', 0), ('VT', 0), ('WA', 1245), ('WI', 1191), ('WV', 0), ('WY', 49)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3mDuring July 2020, there were 0 patients hospitalized in Texas. Nationwide, the total number of patients hospitalized cannot be determined from the available data, as some states have 0 reported hospitalizations, which may indicate missing data.\n",
      "\n",
      "Explanation: I ran an SQL query to sum the hospitalizedIncrease column for each state during July 2020. The result for Texas was 0, which may indicate missing data. The nationwide total cannot be accurately determined due to the missing data in some states.\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'During July 2020, there were 0 patients hospitalized in Texas. Nationwide, the total number of patients hospitalized cannot be determined from the available data, as some states have 0 reported hospitalizations, which may indicate missing data.\\n\\nExplanation: I ran an SQL query to sum the hospitalizedIncrease column for each state during July 2020. The result for Texas was 0, which may indicate missing data. The nationwide total cannot be accurately determined due to the missing data in some states.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_chain(query_str)['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95052aba-d0c5-4883-a0b6-70c20e236b6a",
   "metadata": {},
   "source": [
    "### To use or not use Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564867d7-f261-4e4c-99d3-37cf4e5c5000",
   "metadata": {},
   "source": [
    "As you can see above we achieved our goal of Question->SQL without using an Agent, we did it just by using a clever prompt. (If you want to see the different kind of prompts templates that come with langchain for sql chain, you can check it out [HERE](https://github.com/hwchase17/langchain/blob/master/langchain/chains/sql_database/prompt.py)). **So the question is, why do we need an Agent then?**\n",
    "\n",
    "**This is why**: As we explained on the prior Notebook, an agent is a process in which the LLM self-asks about what approach and steps to take, questions the validity of the results and if sure, provides the answer. The SQLDatabaseChain doesn't do all this analysis, but instead tries a one-shot query in order to answer the question, which is good! but not enough for complex questions. That's why it couldn't solve the part about nationwide, it needs multiple steps in order to solve the problem, one query is not enough.\n",
    "Notice that it did't pay atention to the prompt where we explicitly say to try two methods and reflect on the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8b1352-d6d7-4319-a0b8-ae7b9c2fd234",
   "metadata": {},
   "source": [
    "As homework, try to use an agent instead of a chain and get to the same result as Notebook 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cbc405-26e2-471e-9626-2a0df07f5ddc",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7381ea5f-7269-4e1f-8b0c-1e2c04bd84c0",
   "metadata": {},
   "source": [
    "In this notebook, we achieved our goal of Asking a Question in natural language to a dataset located on a SQL Database.  We did this by using purely prompt engineering (Langchain does it for us) and the cognitive power of GPT-4.\n",
    "\n",
    "This process shows why it is NOT necessary to move the data from its original source as long as the source has an API and a common language we can use to interface with. GPT-4 has been trained on the whole public Github corpus, so it can pretty much understand most of the coding and database query languages that exists out there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f6505da-0114-4b21-8b10-3445344424d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There are many ', 'books', 's', ' in the library. A ', 'BOOK', None, ' is found.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "string = \"There are many books in the library. A BOOK is found.\"\n",
    "split_word = \"book(s)?\"\n",
    "split_regex = re.compile(f\"({split_word})\", re.IGNORECASE)\n",
    "\n",
    "result = split_regex.split(string)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7909556c-3c03-4ecd-b247-3b2357f34344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There are many ', 'in the library. A ', 'is found.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "string = \"There are many books in the library. A BOOK is found.\"\n",
    "split_word = \"book\"\n",
    "split_regex = re.compile(f\"{split_word}s?\\\\W*\", re.IGNORECASE)\n",
    "\n",
    "result = split_regex.split(string)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64946ebf-c7cc-452d-926b-a009c4ffdb5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
